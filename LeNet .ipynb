{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the LeNet network\n",
    "\n",
    "LeNet5 is a small network, it contains the basic modules of deep learning: convolutional layer, pooling layer, and full link layer. It is the basis of other deep learning models. Here we analyze LeNet5 in depth. At the same time, through example analysis, deepen the understanding of the convolutional layer and pooling layer.\n",
    "\n",
    "![lenet](img/lenet-5.png)\n",
    "\n",
    "\n",
    "LeNet-5 Total seven layer , does not comprise an input, each containing a trainable parameters; each layer has a plurality of the Map the Feature , a characteristic of each of the input FeatureMap extracted by means of a convolution filter, and then each FeatureMap There are multiple neurons.\n",
    "\n",
    "![lenet1](img/arch.jpg)\n",
    "\n",
    "#### **Output layer-fully connected layer**\n",
    "\n",
    "The output layer is also a fully connected layer, with a total of 10 nodes, which respectively represent the numbers 0 to 9, and if the value of node i is 0, the result of network recognition is the number i. A radial basis function (RBF) network connection is used. Assuming x is the input of the previous layer and y is the output of the RBF, the calculation of the RBF output is:\n",
    "\n",
    "![lenet1](img/81.png)\n",
    "\n",
    "The value of the above formula w_ij is determined by the bitmap encoding of i, where i ranges from 0 to 9, and j ranges from 0 to 7 * 12-1. The closer the value of the RBF output is to 0, the closer it is to i, that is, the closer to the ASCII encoding figure of i, it means that the recognition result input by the current network is the character i. This layer has 84x10 = 840 parameters and connections.\n",
    "\n",
    "![lenet1](img/82.png)\n",
    "\n",
    "\n",
    "**Summary**\n",
    "\n",
    "\n",
    "* LeNet-5 is a very efficient convolutional neural network for handwritten character recognition.\n",
    "* Convolutional neural networks can make good use of the structural information of images.\n",
    "* The convolutional layer has fewer parameters, which is also determined by the main characteristics of the convolutional layer, that is, local connection and shared weights.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 50s 4us/step\n",
      "WARNING:tensorflow:From C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3655: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3008: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Himanshu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:976: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 22s 371us/step - loss: 0.3415 - acc: 0.8960 - val_loss: 0.1044 - val_acc: 0.9680\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 0.1025 - acc: 0.9680 - val_loss: 0.0889 - val_acc: 0.9723\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 36s 594us/step - loss: 0.0732 - acc: 0.9767 - val_loss: 0.0576 - val_acc: 0.9824\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 38s 629us/step - loss: 0.0559 - acc: 0.9823 - val_loss: 0.0513 - val_acc: 0.9834\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 43s 711us/step - loss: 0.0455 - acc: 0.9853 - val_loss: 0.0460 - val_acc: 0.9848\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 33s 558us/step - loss: 0.0391 - acc: 0.9877 - val_loss: 0.0487 - val_acc: 0.9844\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 42s 698us/step - loss: 0.0339 - acc: 0.9892 - val_loss: 0.0421 - val_acc: 0.9867\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 41s 681us/step - loss: 0.0284 - acc: 0.9910 - val_loss: 0.0413 - val_acc: 0.9873\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.0262 - acc: 0.9914 - val_loss: 0.0362 - val_acc: 0.9883\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.0229 - acc: 0.9926 - val_loss: 0.0483 - val_acc: 0.9854\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0200 - acc: 0.9932 - val_loss: 0.0422 - val_acc: 0.9871\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0380 - val_acc: 0.9892\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.0161 - acc: 0.9946 - val_loss: 0.0398 - val_acc: 0.9889\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 19s 325us/step - loss: 0.0153 - acc: 0.9952 - val_loss: 0.0366 - val_acc: 0.9894\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 33s 551us/step - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0345 - val_acc: 0.9900\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 25s 418us/step - loss: 0.0120 - acc: 0.9960 - val_loss: 0.0445 - val_acc: 0.9892\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 43s 717us/step - loss: 0.0115 - acc: 0.9960 - val_loss: 0.0413 - val_acc: 0.9892\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0487 - val_acc: 0.9869\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 55s 919us/step - loss: 0.0113 - acc: 0.9960 - val_loss: 0.0384 - val_acc: 0.9892\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0416 - val_acc: 0.9894\n",
      "10000/10000 [==============================] - 2s 198us/step\n",
      "Test Loss: 0.04161602752979725\n",
      "Test accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Loading the dataset and perform splitting\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Peforming reshaping operation\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Normalization\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# One Hot Encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "# Building the Model Architecture\n",
    "\n",
    "model = Sequential()\n",
    "# Select 6 feature convolution kernels with a size of 5 * 5 (without offset), and get 66 feature maps. The size of each feature map is 32−5 + 1 = 2832−5 + 1 = 28.\n",
    "# That is, the number of neurons has been reduced from 10241024 to 28 ∗ 28 = 784 28 ∗ 28 = 784.\n",
    "# Parameters between input layer and C1 layer: 6 ∗ (5 ∗ 5 + 1)\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "# The input of this layer is the output of the first layer, which is a 28 * 28 * 6 node matrix.\n",
    "# The size of the filter used in this layer is 2 * 2, and the step length and width are both 2, so the output matrix size of this layer is 14 * 14 * 6.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# The input matrix size of this layer is 14 * 14 * 6, the filter size used is 5 * 5, and the depth is 16. This layer does not use all 0 padding, and the step size is 1.\n",
    "# The output matrix size of this layer is 10 * 10 * 16. This layer has 5 * 5 * 6 * 16 + 16 = 2416 parameters\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "# The input matrix size of this layer is 10 * 10 * 16. The size of the filter used in this layer is 2 * 2, and the length and width steps are both 2, so the output matrix size of this layer is 5 * 5 * 16.\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# The input matrix size of this layer is 5 * 5 * 16. This layer is called a convolution layer in the LeNet-5 paper, but because the size of the filter is 5 * 5, #\n",
    "# So it is not different from the fully connected layer. If the nodes in the 5 * 5 * 16 matrix are pulled into a vector, then this layer is the same as the fully connected layer.\n",
    "# The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "# The number of input nodes in this layer is 120 and the number of output nodes is 84. The total parameter is 120 * 84 + 84 = 10164 (w + b)\n",
    "model.add(Dense(84, activation='relu'))\n",
    "# The number of input nodes in this layer is 84 and the number of output nodes is 10. The total parameter is 84 * 10 + 10 = 850\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[9],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
